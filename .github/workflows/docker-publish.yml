name: Build and Publish Mlflow Docker Image

on:
  push:
    branches: [main]
    # Publish semver tags as releases.
    tags:
      - "*.*.*"
      - "*.*.*.*"
    paths:
      - ".github/workflows/docker-publish.yml"
      - ".env"
      - "poetry.lock"
      - "poetry.toml"
      - "pyproject.toml"
      - "Dockerfile"
      - "mlflowstack/**"
      - "docker-compose.*.yaml"
      - "tests/**"
      - "test-containers/**"

  pull_request:
    branches: [main]

  workflow_dispatch:

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Load .env and generate matrix
        id: set-matrix
        run: |
          set -a
          source .env
          set +a

          MATRIX=$(jq -c -n \
            --arg pg1 "15" \
            --arg pg2 "16" \
            --arg pg3 "$POSTGRES_VERSION" \
            --arg my1 "8.0" \
            --arg my2 "8.4" \
            --arg my3 "$MYSQL_VERSION" \
            --arg minio "$MINIO_VERSION" \
            --arg gcs "$FAKE_GCS_SERVER_VERSION" \
            --arg azurite "$AZURITE_VERSION" \
            --arg azure_blob "$AZURE_STORAGE_BLOB_VERSION" \
            --arg lldap "$LLDAP_VERSION" \
            --arg mssql "$MSSQL_VERSION" \
            '[
              { "postgres": $pg1, "mysql": $my1, "minio": $minio, "gcs": $gcs, "azurite": $azurite, "azure-storage-blob": $azure_blob, "lldap": $lldap, "mssql": $mssql },
              { "postgres": $pg2, "mysql": $my2, "minio": $minio, "gcs": $gcs, "azurite": $azurite, "azure-storage-blob": $azure_blob, "lldap": $lldap, "mssql": $mssql },
              { "postgres": $pg3, "mysql": $my3, "minio": $minio, "gcs": $gcs, "azurite": $azurite, "azure-storage-blob": $azure_blob, "lldap": $lldap, "mssql": $mssql }
            ]')
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
        shell: /usr/bin/bash -e {0}

  integrationtest:
    needs: setup
    runs-on: ubuntu-latest

    strategy:
      matrix:
        database-combo: ${{ fromJson(needs.setup.outputs.matrix) }}

    name: Test PostgreSQL ${{ matrix.database-combo.postgres }} & MySQL ${{ matrix.database-combo.mysql }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Set up python
        id: setup-python
        uses: actions/setup-python@v6
        with:
          python-version: 3.13

      #----------------------------------------------
      #  -----  install & configure poetry  -----
      #----------------------------------------------
      - name: Install Poetry
        uses: snok/install-poetry@v1
        with:
          virtualenvs-create: true
          virtualenvs-in-project: true
          installer-parallel: true

      #----------------------------------------------
      #       load cached venv if cache exists
      #----------------------------------------------
      - name: Load cached venv
        id: cached-poetry-dependencies
        uses: actions/cache@v4
        with:
          path: .venv
          key: venv-${{ runner.os }}-${{ steps.setup-python.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}

      #----------------------------------------------
      # install dependencies if cache does not exist
      #----------------------------------------------
      - name: Install dependencies
        if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
        run: poetry install --no-interaction --no-root

      #----------------------------------------------
      # install your root project, if required
      #----------------------------------------------
      - name: Install library
        run: poetry install --no-interaction

      - name: Cache Docker images
        id: cache-docker-images
        uses: actions/cache@v4
        with:
          path: ${{ github.workspace }}/.docker-cache
          key: ${{ runner.os }}-docker-images-${{ matrix.database-combo.postgres }}-${{ matrix.database-combo.mysql }}-${{ matrix.database-combo.minio }}-${{ matrix.database-combo.gcs }}-${{ matrix.database-combo.azurite }}-${{ matrix.database-combo.lldap }}-${{ matrix.database-combo.mssql }}
          restore-keys: |
            ${{ runner.os }}-docker-images-

      - name: Load Cached Docker Images
        if: steps.cache-docker-images.outputs.cache-hit == 'true'
        run: |
          docker load --input ${{ github.workspace }}/.docker-cache/docker-images.tar

      - name: Pull and Save Docker Images if not Cached
        if: steps.cache-docker-images.outputs.cache-hit != 'true'
        run: |
          mkdir -p ${{ github.workspace }}/.docker-cache
          docker pull postgres:${{ matrix.database-combo.postgres }}
          docker pull mysql:${{ matrix.database-combo.mysql }}
          docker pull minio/minio:${{ matrix.database-combo.minio }}
          docker pull fsouza/fake-gcs-server:${{ matrix.database-combo.gcs }}
          docker pull mcr.microsoft.com/azure-storage/azurite:${{ matrix.database-combo.azurite }}
          docker pull lldap/lldap:${{ matrix.database-combo.lldap }}
          docker pull mcr.microsoft.com/mssql/server:${{ matrix.database-combo.mssql }}

          docker save -o ${{ github.workspace }}/.docker-cache/docker-images.tar \
            postgres:${{ matrix.database-combo.postgres }} \
            mysql:${{ matrix.database-combo.mysql }} \
            minio/minio:${{ matrix.database-combo.minio }} \
            fsouza/fake-gcs-server:${{ matrix.database-combo.gcs }} \
            mcr.microsoft.com/azure-storage/azurite:${{ matrix.database-combo.azurite }} \
            lldap/lldap:${{ matrix.database-combo.lldap }} \
            mcr.microsoft.com/mssql/server:${{ matrix.database-combo.mssql }}

      #----------------------------------------------
      #              run test suite
      #----------------------------------------------
      - name: Run tests
        env:
          POSTGRES_VERSION: ${{ matrix.database-combo.postgres }}
          MYSQL_VERSION: ${{ matrix.database-combo.mysql }}
          MINIO_VERSION: ${{ matrix.database-combo.minio }}
          FAKE_GCS_SERVER_VERSION: ${{ matrix.database-combo.gcs }}
          AZURITE_VERSION: ${{ matrix.database-combo.azurite }}
          AZURE_STORAGE_BLOB_VERSION: ${{ matrix.database-combo.azure-storage-blob }}
          LLDAP_VERSION: ${{ matrix.database-combo.lldap }}
          MSSQL_VERSION: ${{ matrix.database-combo.mssql }}
        run: |
          source .venv/bin/activate
          poetry run pytest

  buildtestpush:
    runs-on: ubuntu-latest

    needs: integrationtest

    env:
      IMAGE_NAME: ${{ github.repository }}

    permissions:
      contents: read
      packages: write
      # This is used to complete the identity challenge
      # with sigstore/fulcio when running outside of PRs.
      id-token: write
      # To upload sarif files
      security-events: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v5

      - name: Install ORAS
        id: install_oras
        uses: oras-project/setup-oras@main

      - name: Install Cosign
        id: install_cosign
        uses: sigstore/cosign-installer@v3.10.0

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3.6.0
        with:
          platforms: all

      # Workaround: https://github.com/docker/build-push-action/issues/461
      - name: Setup Docker buildx
        uses: docker/setup-buildx-action@v3

      # Login against a Docker Hub registry except on PR
      # https://github.com/docker/login-action
      - name: Login to Docker Hub
        id: docker_hub_login
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        uses: docker/login-action@v3
        with:
          registry: docker.io
          username: ${{ github.actor }}
          password: ${{ secrets.DOCKER_HUB_TOKEN }}

      # Login against a Docker registry except on PR
      # https://github.com/docker/login-action
      - name: Login to GitHub Container Registry
        id: ghcr_login
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Login to GitHub Container Registry (ORAS)
        id: oras_ghcr_login
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        run: |
          echo ${{ secrets.GITHUB_TOKEN }} | oras login ghcr.io --username ${{ github.actor }} --password-stdin

      - name: Publish Artifact Hub Manifest
        id: publish_ah_manifest
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        run: |
          oras push \
            ghcr.io/${{ env.IMAGE_NAME }}:artifacthub.io \
            --config /dev/null:application/vnd.cncf.artifacthub.config.v1+yaml \
            artifacthub-repo.yml:application/vnd.cncf.artifacthub.repository-metadata.layer.v1.yaml

      # Extract metadata (tags, labels) for Docker
      # https://github.com/docker/metadata-action
      - name: Extract Docker metadata
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: |
            docker.io/${{ env.IMAGE_NAME }}
            ghcr.io/${{ env.IMAGE_NAME }}
          flavor: |
            latest=true
          tags: |
            type=ref,event=tag
          labels: |
            io.artifacthub.package.readme-url=https://raw.githubusercontent.com/burakince/mlflow/refs/heads/main/README.md
            io.artifacthub.package.maintainers=[{"name":"burakince","email":"burak.ince@linux.org.tr"}]
            io.artifacthub.package.logo-url=https://raw.githubusercontent.com/mlflow/mlflow/master/assets/logo.svg
            io.artifacthub.package.keywords=machine-learning,ai,ml,model-management,mlflow,mlflow-tracking-server,mlflow-docker,mlflow-tracking,mlflow-kube
            io.artifacthub.package.license=MIT
            io.artifacthub.package.alternative-locations=docker.io/${{ env.IMAGE_NAME }}

      - name: Build image for local analysis
        id: build-docker-image
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/amd64
          push: false
          load: true
          tags: docker.io/${{ env.IMAGE_NAME }}:latest
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Run Snyk to check Docker image for vulnerabilities
        id: docker-image-scan
        continue-on-error: true
        uses: snyk/actions/docker@v1.0.0
        env:
          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}
        with:
          image: docker.io/${{ env.IMAGE_NAME }}:latest
          args: --file=Dockerfile --severity-threshold=medium --sarif-file-output=snyk.sarif

      - name: Upload result to GitHub Code Scanning
        if: hashFiles('snyk.sarif') != ''
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: snyk.sarif

      # Break the pipeline with failure status if security scan failed
      # - name: Check docker image scan status
      #   if: ${{ steps.docker-image-scan.outcome == 'failure' }}
      #   run: exit 1

      # - name: Install Dive
      #   run: |
      #     set -e
      #     retries=5
      #     delay=10
      #     for ((i=1; i<=retries; i++)); do
      #       echo "Attempt $i of $retries"
      #       # Fetch the latest dive version
      #       DIVE_VERSION=$(curl -sL -H "Accept: application/vnd.github+json" "https://api.github.com/repos/wagoodman/dive/releases/latest" | grep '"tag_name":' | sed -E 's/.*"v([^"]+)".*/\1/')
      #       if [ -z "$DIVE_VERSION" ]; then
      #         echo "Failed to fetch DIVE_VERSION"
      #         if [ $i -eq $retries ]; then
      #           echo "All attempts to fetch DIVE_VERSION failed"
      #           exit 1
      #         fi
      #         sleep $delay
      #         continue
      #       fi
      #       echo "DIVE_VERSION: $DIVE_VERSION"
      #       # Download the .deb file
      #       curl -OL --fail --retry 3 --retry-delay 5 "https://github.com/wagoodman/dive/releases/download/v${DIVE_VERSION}/dive_${DIVE_VERSION}_linux_amd64.deb"
      #       if [ $? -ne 0 ]; then
      #         echo "Failed to download dive_${DIVE_VERSION}_linux_amd64.deb"
      #         if [ $i -eq $retries ]; then
      #           echo "All attempts to download .deb file failed"
      #           exit 1
      #         fi
      #         sleep $delay
      #         continue
      #       fi
      #       # Verify the .deb file
      #       file dive_${DIVE_VERSION}_linux_amd64.deb | grep "Debian binary package" || {
      #         echo "Downloaded file is not a valid .deb package"
      #         if [ $i -eq $retries ]; then
      #           echo "All attempts to download a valid .deb file failed"
      #           exit 1
      #         fi
      #         rm -f dive_${DIVE_VERSION}_linux_amd64.deb
      #         sleep $delay
      #         continue
      #       }
      #       # Install the .deb file
      #       sudo apt install -y ./dive_${DIVE_VERSION}_linux_amd64.deb
      #       if [ $? -eq 0 ]; then
      #         echo "Dive installed successfully"
      #         exit 0
      #       else
      #         echo "Failed to install dive_${DIVE_VERSION}_linux_amd64.deb"
      #         if [ $i -eq $retries ]; then
      #           echo "All attempts to install dive failed"
      #           exit 1
      #         fi
      #         rm -f dive_${DIVE_VERSION}_linux_amd64.deb
      #         sleep $delay
      #       fi
      #     done

      # - name: Analyse Efficiency and Wastes on Image
      #   run: dive docker.io/${{ env.IMAGE_NAME }}:latest

      - name: Ensure the image can be cross-compiled
        if: github.event_name == 'pull_request'
        id: cross-compile-check
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/arm64/v8,linux/amd64
          push: false
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # Build again and push Docker image with Buildx (don't push on PR)
      # https://github.com/docker/build-push-action
      - name: Build and push Docker image
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        id: build-and-push
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/arm64/v8,linux/amd64
          push: true
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      # Sign the resulting Docker image digest except on PRs.
      # This will only write to the public Rekor transparency log when the Docker
      # repository is public to avoid leaking data.  If you would like to publish
      # transparency data even for private images, pass --force to cosign below.
      # https://github.com/sigstore/cosign
      - name: Sign the published Docker images
        if: github.event_name != 'pull_request' && contains(github.ref, 'refs/tags/')
        run: |
          echo "${{ steps.meta.outputs.tags }}" | xargs -I {} cosign sign -y {}@${{ steps.build-and-push.outputs.digest }}
